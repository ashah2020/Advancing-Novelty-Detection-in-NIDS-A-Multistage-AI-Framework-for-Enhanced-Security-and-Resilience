{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e50224e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras import Sequential,layers, losses, optimizers\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5fb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load CICIDS 2017 training dataset\n",
    "df_train = pd.read_csv(\"all_group_train_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee8dc0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign          53432\n",
       "DoS              8906\n",
       "Web Attack       8906\n",
       "Infiltration     8905\n",
       "Port Scan        8905\n",
       "DDoS             8905\n",
       "Brute Force      8905\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d638bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading CICIDS217 test dataset\n",
    "df_test = pd.read_csv(\"all_group_test_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aacaa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3817, 200)\n",
      "(3817, 200)\n",
      "(3817, 200)\n",
      "(3817, 200)\n",
      "(3816, 200)\n",
      "(3816, 200)\n",
      "(22900, 200)\n"
     ]
    }
   ],
   "source": [
    "## Subsetting attack packets from CICIDS 2017 dataset\n",
    "infiltration_attack = df_test[df_test['Label'] == 'Infiltration'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(infiltration_attack.shape)\n",
    "portscan_attack = df_test[df_test['Label'] == 'Port Scan'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(portscan_attack.shape)\n",
    "ddos_attack = df_test[df_test['Label'] == 'DDoS'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(ddos_attack.shape)\n",
    "bruteforce_attack = df_test[df_test['Label'] == 'Brute Force'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(bruteforce_attack.shape)\n",
    "dos_attack = df_test[df_test['Label'] == 'DoS'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(dos_attack.shape)\n",
    "web_attack = df_test[df_test['Label'] == 'Web Attack'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(web_attack.shape)\n",
    "benign_data = df_test[df_test['Label'] == 'Benign'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(benign_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eee99bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_header_byte_2</th>\n",
       "      <th>ip_header_byte_3</th>\n",
       "      <th>ip_header_byte_4</th>\n",
       "      <th>ip_header_byte_5</th>\n",
       "      <th>ip_header_byte_6</th>\n",
       "      <th>ip_header_byte_7</th>\n",
       "      <th>ip_header_byte_8</th>\n",
       "      <th>ip_header_byte_10</th>\n",
       "      <th>ip_header_byte_11</th>\n",
       "      <th>tcp_header_byte_4</th>\n",
       "      <th>...</th>\n",
       "      <th>tcp_segment_data_byte_125</th>\n",
       "      <th>tcp_segment_data_byte_126</th>\n",
       "      <th>tcp_segment_data_byte_127</th>\n",
       "      <th>tcp_segment_data_byte_128</th>\n",
       "      <th>tcp_segment_data_byte_129</th>\n",
       "      <th>tcp_segment_data_byte_130</th>\n",
       "      <th>tcp_segment_data_byte_131</th>\n",
       "      <th>tcp_segment_data_byte_132</th>\n",
       "      <th>tcp_segment_data_byte_133</th>\n",
       "      <th>tcp_segment_data_byte_134</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45759</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45761</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45768</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45781</th>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.180392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45790</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.486275</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3817 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip_header_byte_2  ip_header_byte_3  ip_header_byte_4  ip_header_byte_5  \\\n",
       "5              0.007843          0.109804          0.054902          0.980392   \n",
       "14             0.003922          0.717647          0.286275          0.760784   \n",
       "16             0.003922          0.835294          0.172549          0.192157   \n",
       "19             0.007843          0.109804          0.054902          0.494118   \n",
       "28             0.007843          0.109804          0.145098          0.443137   \n",
       "...                 ...               ...               ...               ...   \n",
       "45759          0.003922          0.133333          0.215686          0.541176   \n",
       "45761          0.007843          0.686275          0.180392          0.145098   \n",
       "45768          0.000000          0.270588          0.086275          0.329412   \n",
       "45781          0.011765          0.168627          0.462745          0.356863   \n",
       "45790          0.007843          0.109804          0.486275          0.407843   \n",
       "\n",
       "       ip_header_byte_6  ip_header_byte_7  ip_header_byte_8  \\\n",
       "5               0.25098               0.0          0.501961   \n",
       "14              0.25098               0.0          0.501961   \n",
       "16              0.25098               0.0          0.501961   \n",
       "19              0.25098               0.0          0.501961   \n",
       "28              0.25098               0.0          0.501961   \n",
       "...                 ...               ...               ...   \n",
       "45759           0.25098               0.0          0.501961   \n",
       "45761           0.25098               0.0          0.501961   \n",
       "45768           0.25098               0.0          0.501961   \n",
       "45781           0.25098               0.0          0.501961   \n",
       "45790           0.25098               0.0          0.501961   \n",
       "\n",
       "       ip_header_byte_10  ip_header_byte_11  tcp_header_byte_4  ...  \\\n",
       "5               0.674510           0.223529           0.196078  ...   \n",
       "14              0.443137           0.839216           0.929412  ...   \n",
       "16              0.560784           0.286275           0.196078  ...   \n",
       "19              0.674510           0.709804           0.196078  ...   \n",
       "28              0.584314           0.760784           0.929412  ...   \n",
       "...                  ...                ...                ...  ...   \n",
       "45759           0.517647           0.639216           0.196078  ...   \n",
       "45761           0.549020           0.482353           0.196078  ...   \n",
       "45768           0.650980           0.713725           0.196078  ...   \n",
       "45781           0.262745           0.788235           0.192157  ...   \n",
       "45790           0.243137           0.796078           0.196078  ...   \n",
       "\n",
       "       tcp_segment_data_byte_125  tcp_segment_data_byte_126  \\\n",
       "5                       0.152941                   0.431373   \n",
       "14                      0.152941                   0.431373   \n",
       "16                      0.050980                   0.039216   \n",
       "19                      0.152941                   0.431373   \n",
       "28                      0.152941                   0.431373   \n",
       "...                          ...                        ...   \n",
       "45759                   0.050980                   0.039216   \n",
       "45761                   0.152941                   0.431373   \n",
       "45768                   0.000000                   0.000000   \n",
       "45781                   0.450980                   0.298039   \n",
       "45790                   0.152941                   0.431373   \n",
       "\n",
       "       tcp_segment_data_byte_127  tcp_segment_data_byte_128  \\\n",
       "5                       0.427451                   0.380392   \n",
       "14                      0.427451                   0.380392   \n",
       "16                      0.262745                   0.227451   \n",
       "19                      0.427451                   0.380392   \n",
       "28                      0.427451                   0.380392   \n",
       "...                          ...                        ...   \n",
       "45759                   0.262745                   0.227451   \n",
       "45761                   0.427451                   0.380392   \n",
       "45768                   0.000000                   0.000000   \n",
       "45781                   0.125490                   0.176471   \n",
       "45790                   0.427451                   0.380392   \n",
       "\n",
       "       tcp_segment_data_byte_129  tcp_segment_data_byte_130  \\\n",
       "5                       0.439216                   0.152941   \n",
       "14                      0.439216                   0.152941   \n",
       "16                      0.360784                   0.243137   \n",
       "19                      0.439216                   0.152941   \n",
       "28                      0.439216                   0.152941   \n",
       "...                          ...                        ...   \n",
       "45759                   0.360784                   0.243137   \n",
       "45761                   0.439216                   0.152941   \n",
       "45768                   0.000000                   0.000000   \n",
       "45781                   0.431373                   0.125490   \n",
       "45790                   0.439216                   0.152941   \n",
       "\n",
       "       tcp_segment_data_byte_131  tcp_segment_data_byte_132  \\\n",
       "5                       0.125490                   0.411765   \n",
       "14                      0.125490                   0.411765   \n",
       "16                      0.431373                   0.427451   \n",
       "19                      0.125490                   0.411765   \n",
       "28                      0.125490                   0.411765   \n",
       "...                          ...                        ...   \n",
       "45759                   0.431373                   0.427451   \n",
       "45761                   0.125490                   0.411765   \n",
       "45768                   0.000000                   0.000000   \n",
       "45781                   0.192157                   0.223529   \n",
       "45790                   0.125490                   0.411765   \n",
       "\n",
       "       tcp_segment_data_byte_133  tcp_segment_data_byte_134  \n",
       "5                       0.450980                   0.125490  \n",
       "14                      0.450980                   0.125490  \n",
       "16                      0.380392                   0.439216  \n",
       "19                      0.450980                   0.125490  \n",
       "28                      0.450980                   0.125490  \n",
       "...                          ...                        ...  \n",
       "45759                   0.380392                   0.439216  \n",
       "45761                   0.450980                   0.125490  \n",
       "45768                   0.000000                   0.000000  \n",
       "45781                   0.196078                   0.180392  \n",
       "45790                   0.450980                   0.125490  \n",
       "\n",
       "[3817 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infiltration_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b58a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading CICIDS 2018 training data\n",
    "df_test_2018 = pd.read_csv(\"all_group_train_normalized_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5e3271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_2018 = df_test_2018.sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b4049c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_header_byte_2</th>\n",
       "      <th>ip_header_byte_3</th>\n",
       "      <th>ip_header_byte_4</th>\n",
       "      <th>ip_header_byte_5</th>\n",
       "      <th>ip_header_byte_6</th>\n",
       "      <th>ip_header_byte_7</th>\n",
       "      <th>ip_header_byte_8</th>\n",
       "      <th>ip_header_byte_10</th>\n",
       "      <th>ip_header_byte_11</th>\n",
       "      <th>tcp_header_byte_4</th>\n",
       "      <th>...</th>\n",
       "      <th>tcp_segment_data_byte_1452</th>\n",
       "      <th>tcp_segment_data_byte_1453</th>\n",
       "      <th>tcp_segment_data_byte_1454</th>\n",
       "      <th>tcp_segment_data_byte_1455</th>\n",
       "      <th>tcp_segment_data_byte_1456</th>\n",
       "      <th>tcp_segment_data_byte_1457</th>\n",
       "      <th>tcp_segment_data_byte_1458</th>\n",
       "      <th>tcp_segment_data_byte_1459</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Web Attack</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DoS</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.807843</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Infiltration</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291153</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brute Force</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291154</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291155</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Infiltration</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291156</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291157</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291158 rows × 1527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ip_header_byte_2  ip_header_byte_3  ip_header_byte_4  \\\n",
       "0               0.003922          0.576471          0.219608   \n",
       "1               0.007843          0.792157          0.839216   \n",
       "2               0.000000          0.156863          0.309804   \n",
       "3               0.000000          0.156863          0.168627   \n",
       "4               0.000000          0.156863          0.188235   \n",
       "...                  ...               ...               ...   \n",
       "291153          0.000000          0.235294          0.023529   \n",
       "291154          0.000000          0.156863          0.372549   \n",
       "291155          0.000000          0.976471          0.058824   \n",
       "291156          0.000000          0.156863          0.372549   \n",
       "291157          0.000000          0.156863          0.321569   \n",
       "\n",
       "        ip_header_byte_5  ip_header_byte_6  ip_header_byte_7  \\\n",
       "0               0.678431           0.25098               0.0   \n",
       "1               0.407843           0.25098               0.0   \n",
       "2               0.772549           0.25098               0.0   \n",
       "3               0.537255           0.25098               0.0   \n",
       "4               0.603922           0.25098               0.0   \n",
       "...                  ...               ...               ...   \n",
       "291153          0.450980           0.25098               0.0   \n",
       "291154          0.388235           0.25098               0.0   \n",
       "291155          0.298039           0.25098               0.0   \n",
       "291156          0.498039           0.25098               0.0   \n",
       "291157          0.239216           0.25098               0.0   \n",
       "\n",
       "        ip_header_byte_8  ip_header_byte_10  ip_header_byte_11  \\\n",
       "0               0.250980           0.537255           0.400000   \n",
       "1               0.250980           0.541176           0.152941   \n",
       "2               0.501961           0.807843           0.713725   \n",
       "3               0.250980           0.172549           0.870588   \n",
       "4               0.501961           0.231373           0.847059   \n",
       "...                  ...                ...                ...   \n",
       "291153          0.247059           0.337255           0.184314   \n",
       "291154          0.501961           0.749020           0.094118   \n",
       "291155          0.415686           0.482353           0.219608   \n",
       "291156          0.501961           0.745098           0.988235   \n",
       "291157          0.501961           0.760784           0.756863   \n",
       "\n",
       "        tcp_header_byte_4  ...  tcp_segment_data_byte_1452  \\\n",
       "0                0.419608  ...                         0.0   \n",
       "1                0.333333  ...                         0.0   \n",
       "2                0.356863  ...                         0.0   \n",
       "3                0.000000  ...                         0.0   \n",
       "4                0.274510  ...                         0.0   \n",
       "...                   ...  ...                         ...   \n",
       "291153           0.803922  ...                         0.0   \n",
       "291154           0.356863  ...                         0.0   \n",
       "291155           0.937255  ...                         0.0   \n",
       "291156           0.356863  ...                         0.0   \n",
       "291157           0.776471  ...                         0.0   \n",
       "\n",
       "        tcp_segment_data_byte_1453  tcp_segment_data_byte_1454  \\\n",
       "0                              0.0                         0.0   \n",
       "1                              0.0                         0.0   \n",
       "2                              0.0                         0.0   \n",
       "3                              0.0                         0.0   \n",
       "4                              0.0                         0.0   \n",
       "...                            ...                         ...   \n",
       "291153                         0.0                         0.0   \n",
       "291154                         0.0                         0.0   \n",
       "291155                         0.0                         0.0   \n",
       "291156                         0.0                         0.0   \n",
       "291157                         0.0                         0.0   \n",
       "\n",
       "        tcp_segment_data_byte_1455  tcp_segment_data_byte_1456  \\\n",
       "0                              0.0                         0.0   \n",
       "1                              0.0                         0.0   \n",
       "2                              0.0                         0.0   \n",
       "3                              0.0                         0.0   \n",
       "4                              0.0                         0.0   \n",
       "...                            ...                         ...   \n",
       "291153                         0.0                         0.0   \n",
       "291154                         0.0                         0.0   \n",
       "291155                         0.0                         0.0   \n",
       "291156                         0.0                         0.0   \n",
       "291157                         0.0                         0.0   \n",
       "\n",
       "        tcp_segment_data_byte_1457  tcp_segment_data_byte_1458  \\\n",
       "0                              0.0                         0.0   \n",
       "1                              0.0                         0.0   \n",
       "2                              0.0                         0.0   \n",
       "3                              0.0                         0.0   \n",
       "4                              0.0                         0.0   \n",
       "...                            ...                         ...   \n",
       "291153                         0.0                         0.0   \n",
       "291154                         0.0                         0.0   \n",
       "291155                         0.0                         0.0   \n",
       "291156                         0.0                         0.0   \n",
       "291157                         0.0                         0.0   \n",
       "\n",
       "        tcp_segment_data_byte_1459         Label  Label_binary  \n",
       "0                              0.0    Web Attack     Malicious  \n",
       "1                              0.0           DoS     Malicious  \n",
       "2                              0.0        Benign        Benign  \n",
       "3                              0.0  Infiltration     Malicious  \n",
       "4                              0.0        Benign        Benign  \n",
       "...                            ...           ...           ...  \n",
       "291153                         0.0   Brute Force     Malicious  \n",
       "291154                         0.0        Benign        Benign  \n",
       "291155                         0.0  Infiltration     Malicious  \n",
       "291156                         0.0        Benign        Benign  \n",
       "291157                         0.0        Benign        Benign  \n",
       "\n",
       "[291158 rows x 1527 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e567e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2018 = df_test_2018.iloc[:,0:1525]\n",
    "Y_train_2018 = df_test_2018.iloc[:,1526:1527]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac7d864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2017 = df_test.iloc[:,0:1525]\n",
    "Y_train_2017 = df_test.iloc[:,1526:1527]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a88af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_2017.loc[Y_train_2017['Label_binary'] == 'Benign', 'Label_binary'] = 0\n",
    "Y_train_2017.loc[Y_train_2017['Label_binary'] == 'Malicious', 'Label_binary'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a817f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_2018.loc[Y_train_2018['Label_binary'] == 'Benign', 'Label_binary'] = 0\n",
    "Y_train_2018.loc[Y_train_2018['Label_binary'] == 'Malicious', 'Label_binary'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89982815",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_total = pd.concat([X_train_2017,X_train_2018])\n",
    "Y_train_total = pd.concat([Y_train_2017,Y_train_2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef3e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = X_train_total.values.astype('float32')\n",
    "Y_train_ = Y_train_total.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c320991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a6a8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29116, 200)\n",
      "(0, 200)\n",
      "(29115, 200)\n",
      "(29116, 200)\n",
      "(29116, 200)\n",
      "(29116, 200)\n",
      "(145579, 200)\n"
     ]
    }
   ],
   "source": [
    "## Subsetting atatck apckets from CICIDS 2018 dataset\n",
    "infiltration_attack_2018 = df_test_2018[df_test_2018['Label'] == 'Infiltration'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(infiltration_attack_2018.shape)\n",
    "portscan_attack_2018 = df_test_2018[df_test_2018['Label'] == 'Port Scan'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(portscan_attack_2018.shape)\n",
    "ddos_attack_2018 = df_test_2018[df_test_2018['Label'] == 'ddos'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(ddos_attack_2018.shape)\n",
    "bruteforce_attack_2018 = df_test_2018[df_test_2018['Label'] == 'Brute Force'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(bruteforce_attack_2018.shape)\n",
    "dos_attack_2018 = df_test_2018[df_test_2018['Label'] == 'DoS'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(dos_attack_2018.shape)\n",
    "web_attack_2018 = df_test_2018[df_test_2018['Label'] == 'Web Attack'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(web_attack_2018.shape)\n",
    "benign_data_2018 = df_test_2018[df_test_2018['Label'] == 'Benign'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(benign_data_2018.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbf3f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_data_total = pd.concat([benign_data, benign_data_2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77495139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train.loc[Y_train['Label_binary'] == 'Benign', 'Label_binary'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2638e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the baseline stage 2 AE model\n",
    "stage2_AE = tf.keras.models.load_model('Stage2_AE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "066fc79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the pbRe reconstruction metric\n",
    "def recon_metrices(data, reconstructed_data):\n",
    "\n",
    "    maes = np.absolute(data.values - reconstructed_data)\n",
    "    \n",
    "    for j in range(len(maes)):\n",
    "        m = maes[j]\n",
    "        d = data.values[j]\n",
    "        r = reconstructed_data[j]\n",
    "        for el in range(len(m)):\n",
    "            if r[el] == 0 or d[el] == 0:\n",
    "                m[el] = 0\n",
    " \n",
    "            \n",
    "    mae_byte_list = []\n",
    "    ip_mae_list = []\n",
    "    tcp_header_mae_list = []\n",
    "    tcp_options_mae_list = []\n",
    "    tcp_segment_mae_list = []\n",
    "    i=0\n",
    "    for mae in maes:\n",
    "#         print(np.count_nonzero(reconstructed_data[i]))\n",
    "#         print(np.count_nonzero(data.values[i]))\n",
    "#         print(np.max(np.count_nonzero(reconstructed_data[i]),np.count_nonzero(data.values[i])))\n",
    "        mae_byte = sum(mae) / np.count_nonzero(mae)\n",
    "        mae_byte_list.append(mae_byte)\n",
    "        i += 1\n",
    "    return mae_byte_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3527b235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "inf = stage2_AE.predict(infiltration_attack.values.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa5ebe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_byte_list = recon_metrices(infiltration_attack,inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3662ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992140424417082\n"
     ]
    }
   ],
   "source": [
    "## Classification\n",
    "count_99 = len([i for i in mae_byte_list if i > 0.09])\n",
    "print(count_99 / len(mae_byte_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6b19ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retraining with CICIDS 2018 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cfcbf8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modifiable layers\n",
    "mod_layers = [6,7,8,10,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fbea7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modifiable neurons in modifiable layers\n",
    "layer6_ind = [h for h in range(0,50,3)]\n",
    "layer7_ind = [h for h in range(0,25,3)]\n",
    "layer8_ind = [h for h in range(0,12,3)]\n",
    "layer9_ind = []\n",
    "layer10_ind = [h for h in range(0,11,3)]\n",
    "layer11_ind = [h for h in range(0,25,3)]\n",
    "layer12_ind = [h for h in range(0,50,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc0888ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing a new autoencoder model\n",
    "retrained_stage2 = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f81de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "44f97cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture of the retrained model\n",
    "for i, layer in enumerate(stage2_AE.layers):\n",
    "    if i not in mod_layers:\n",
    "        layer.trainable = False\n",
    "        retrained_stage2.add(layer)\n",
    "    else:\n",
    "        retrained_stage2.add(layer)\n",
    "        if i == 6:\n",
    "            for ind in range(0,50):\n",
    "                if ind in layer6_ind:\n",
    "                    retrained_stage2.layers[-1].kernel[ind]._trainable = False\n",
    "            retrained_stage2.add(Dense(50, activation='relu', name = 'Trainable1'))\n",
    "        if i == 7:\n",
    "            for ind in range(0,25):\n",
    "                if ind in layer7_ind:\n",
    "                    retrained_stage2.layers[-1].kernel[ind]._trainable = False\n",
    "                    \n",
    "        if i == 8:\n",
    "            for ind in range(0,12):\n",
    "                if ind in layer8_ind:\n",
    "                    retrained_stage2.layers[-1].kernel[ind]._trainable = False\n",
    "        \n",
    "        if i == 10:\n",
    "            for ind in range(0,6):\n",
    "                if ind in layer10_ind:\n",
    "                    retrained_stage2.layers[-1].kernel[ind]._trainable = False\n",
    "        \n",
    "        if i == 11:\n",
    "            for ind in range(0,12):\n",
    "                if ind in layer11_ind:\n",
    "                    retrained_stage2.layers[-1].kernel[ind]._trainable = False\n",
    "        if i == 12:\n",
    "            for ind in range(0,25):\n",
    "                if ind in layer12_ind:\n",
    "                    retrained_stage2.layers[-1].kernel[ind]._trainable = False\n",
    "            retrained_stage2.add(Dense(50, activation='relu', name = 'Trainable2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04b0f070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 150)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 150)               22650     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 150)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " Trainable1 (Dense)          (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 12)                312       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 12)                84        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 25)                325       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 50)                1300      \n",
      "                                                                 \n",
      " Trainable2 (Dense)          (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 150)               15150     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 150)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 150)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 200)               30200     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,724\n",
      "Trainable params: 13,446\n",
      "Non-trainable params: 181,278\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "retrained_stage2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f1e14323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0434\n",
      "Epoch 2/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0418\n",
      "Epoch 3/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0411\n",
      "Epoch 4/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0408\n",
      "Epoch 5/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0405\n",
      "Epoch 6/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0404\n",
      "Epoch 7/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0402\n",
      "Epoch 8/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0401\n",
      "Epoch 9/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0400\n",
      "Epoch 10/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0399\n",
      "Epoch 11/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0398\n",
      "Epoch 12/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0397\n",
      "Epoch 13/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0396\n",
      "Epoch 14/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0396\n",
      "Epoch 15/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0394\n",
      "Epoch 16/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0394\n",
      "Epoch 17/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0346\n",
      "Epoch 18/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0321\n",
      "Epoch 19/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0319\n",
      "Epoch 20/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0319\n",
      "Epoch 21/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0318\n",
      "Epoch 22/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0317\n",
      "Epoch 23/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0316\n",
      "Epoch 24/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0314\n",
      "Epoch 25/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0312\n",
      "Epoch 26/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0311\n",
      "Epoch 27/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0310\n",
      "Epoch 28/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0310\n",
      "Epoch 29/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0309\n",
      "Epoch 30/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0309\n",
      "Epoch 31/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0308\n",
      "Epoch 32/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0308\n",
      "Epoch 33/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0308\n",
      "Epoch 34/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0307\n",
      "Epoch 35/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0307\n",
      "Epoch 36/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0306\n",
      "Epoch 37/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0306\n",
      "Epoch 38/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0306\n",
      "Epoch 39/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0306\n",
      "Epoch 40/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0306\n",
      "Epoch 41/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0305\n",
      "Epoch 42/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0305\n",
      "Epoch 43/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0304\n",
      "Epoch 44/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0304\n",
      "Epoch 45/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0304\n",
      "Epoch 46/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0304\n",
      "Epoch 47/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0304\n",
      "Epoch 48/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0303\n",
      "Epoch 49/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0304\n",
      "Epoch 50/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0303\n",
      "Epoch 51/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0303\n",
      "Epoch 52/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0303\n",
      "Epoch 53/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0303\n",
      "Epoch 54/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0303\n",
      "Epoch 55/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0303\n",
      "Epoch 56/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0303\n",
      "Epoch 57/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 58/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 59/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 60/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 61/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 62/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 63/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 64/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 65/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 66/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 67/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 68/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0302\n",
      "Epoch 69/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0301\n",
      "Epoch 70/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0301\n",
      "Epoch 71/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0301\n",
      "Epoch 72/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0301\n",
      "Epoch 73/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0301\n",
      "Epoch 74/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0301\n",
      "Epoch 75/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0301\n",
      "Epoch 76/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0301\n",
      "Epoch 77/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 78/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 79/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 80/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 81/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 82/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 83/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 84/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 85/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 86/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 87/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 88/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 89/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 90/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 91/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 92/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 93/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 94/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 95/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 96/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 97/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 98/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 99/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 100/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 101/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 102/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 103/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 104/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 105/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0300\n",
      "Epoch 106/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 107/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 108/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 109/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 110/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 111/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 112/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 113/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 114/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0299\n",
      "Epoch 115/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0299\n",
      "Epoch 116/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0299\n",
      "Epoch 117/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0299\n",
      "Epoch 118/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0299\n",
      "Epoch 119/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0299\n",
      "Epoch 120/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0299\n",
      "Epoch 121/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0298\n",
      "Epoch 122/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0299\n",
      "Epoch 123/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0298\n",
      "Epoch 124/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0299\n",
      "Epoch 125/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0298\n",
      "Epoch 126/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0299\n",
      "Epoch 127/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0298\n",
      "Epoch 128/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0298\n",
      "Epoch 129/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0298\n",
      "Epoch 130/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0298\n",
      "Epoch 131/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0298\n",
      "Epoch 132/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0298\n",
      "Epoch 133/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0298\n",
      "Epoch 134/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0298\n",
      "Epoch 135/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 136/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 137/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 138/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 139/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 140/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 141/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 142/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 143/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 144/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 145/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 146/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 147/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 148/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 149/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0299\n",
      "Epoch 150/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 151/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 152/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 153/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 154/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 155/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0298\n",
      "Epoch 156/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 157/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 158/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 159/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 160/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 161/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 162/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 163/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 164/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 165/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 166/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 167/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 168/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 169/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 170/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 171/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 172/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 173/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 174/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 175/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 176/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 177/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 178/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 179/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 180/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 181/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 182/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 183/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0297\n",
      "Epoch 184/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 185/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 186/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 187/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 188/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 189/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 190/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 191/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 192/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 193/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 194/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 195/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 196/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 197/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 198/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 199/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 200/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 201/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 202/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 203/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0296\n",
      "Epoch 204/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 205/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 206/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 207/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 208/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 209/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 210/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 211/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 212/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 213/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 214/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 215/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0296\n",
      "Epoch 216/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 217/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0295\n",
      "Epoch 218/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0295\n",
      "Epoch 219/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0297\n",
      "Epoch 220/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0296\n",
      "Epoch 221/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0297\n",
      "Epoch 222/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0296\n",
      "Epoch 223/500\n",
      "659/659 [==============================] - 7s 10ms/step - loss: 0.0295\n",
      "Epoch 224/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0296\n",
      "Epoch 225/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0296\n",
      "Epoch 226/500\n",
      "659/659 [==============================] - 7s 11ms/step - loss: 0.0295\n",
      "Epoch 227/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0295\n",
      "Epoch 228/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0295\n",
      "Epoch 229/500\n",
      "659/659 [==============================] - 7s 10ms/step - loss: 0.0295\n",
      "Epoch 230/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0295\n",
      "Epoch 231/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 232/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 233/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 234/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 235/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0295\n",
      "Epoch 236/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 237/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 238/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 239/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 240/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 241/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 242/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 243/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 244/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 245/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 246/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 247/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 248/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 249/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0295\n",
      "Epoch 250/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0295\n",
      "Epoch 251/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 252/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 253/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0294\n",
      "Epoch 254/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0295\n",
      "Epoch 255/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0295\n",
      "Epoch 256/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0295\n",
      "Epoch 257/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0295\n",
      "Epoch 258/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0295\n",
      "Epoch 259/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0295\n",
      "Epoch 260/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 261/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0295\n",
      "Epoch 262/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0295\n",
      "Epoch 263/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0295\n",
      "Epoch 264/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0294\n",
      "Epoch 265/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0294\n",
      "Epoch 266/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 267/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0294\n",
      "Epoch 268/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0294\n",
      "Epoch 269/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0294\n",
      "Epoch 270/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0295\n",
      "Epoch 271/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0295\n",
      "Epoch 272/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 273/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 274/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0294\n",
      "Epoch 275/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0295\n",
      "Epoch 276/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 277/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0294\n",
      "Epoch 278/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0294\n",
      "Epoch 279/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0294\n",
      "Epoch 280/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0294\n",
      "Epoch 281/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0294\n",
      "Epoch 282/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 283/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0295\n",
      "Epoch 284/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0294\n",
      "Epoch 285/500\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0294\n",
      "Epoch 286/500\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0294\n",
      "Epoch 287/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 288/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 289/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 290/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0295\n",
      "Epoch 291/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 292/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0294\n",
      "Epoch 293/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0294\n",
      "Epoch 294/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0294\n",
      "Epoch 295/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0295\n",
      "Epoch 296/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 297/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0294\n",
      "Epoch 298/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0294\n",
      "Epoch 299/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 300/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0294\n",
      "Epoch 301/500\n",
      "659/659 [==============================] - 6s 8ms/step - loss: 0.0294\n",
      "Epoch 302/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 303/500\n",
      "659/659 [==============================] - 6s 10ms/step - loss: 0.0294\n",
      "Epoch 304/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0294\n",
      "Epoch 305/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 306/500\n",
      "659/659 [==============================] - 6s 10ms/step - loss: 0.0294\n",
      "Epoch 307/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0294\n",
      "Epoch 308/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 309/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0294\n",
      "Epoch 310/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 311/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 312/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0294\n",
      "Epoch 313/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0294\n",
      "Epoch 314/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 315/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0294\n",
      "Epoch 316/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0294\n",
      "Epoch 317/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0294\n",
      "Epoch 318/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 319/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 320/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 321/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 322/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 323/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 324/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0294\n",
      "Epoch 325/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 326/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 327/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 328/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 329/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 330/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 331/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0294\n",
      "Epoch 332/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 333/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 334/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 335/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0294\n",
      "Epoch 336/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 337/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 338/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 339/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0293\n",
      "Epoch 340/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 341/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 342/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0293\n",
      "Epoch 343/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 344/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 345/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 346/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 347/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 348/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 349/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 350/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 351/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 352/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 353/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0293\n",
      "Epoch 354/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 355/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 356/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 357/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0293\n",
      "Epoch 358/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 359/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 360/500\n",
      "659/659 [==============================] - 6s 8ms/step - loss: 0.0293\n",
      "Epoch 361/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0293\n",
      "Epoch 362/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 363/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 364/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 365/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 366/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 367/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0293\n",
      "Epoch 368/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 369/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 370/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 371/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 372/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 373/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 374/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 375/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 376/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 377/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 378/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 379/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 380/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 381/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 382/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 383/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 384/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 385/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0294\n",
      "Epoch 386/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0293\n",
      "Epoch 387/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 388/500\n",
      "659/659 [==============================] - 7s 11ms/step - loss: 0.0293\n",
      "Epoch 389/500\n",
      "659/659 [==============================] - 6s 10ms/step - loss: 0.0293\n",
      "Epoch 390/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 391/500\n",
      "659/659 [==============================] - 7s 11ms/step - loss: 0.0293\n",
      "Epoch 392/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 393/500\n",
      "659/659 [==============================] - 7s 10ms/step - loss: 0.0293\n",
      "Epoch 394/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 395/500\n",
      "659/659 [==============================] - 6s 8ms/step - loss: 0.0293\n",
      "Epoch 396/500\n",
      "659/659 [==============================] - 7s 11ms/step - loss: 0.0293\n",
      "Epoch 397/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0293\n",
      "Epoch 398/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 399/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 400/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 401/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 402/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0293\n",
      "Epoch 403/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 404/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 405/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 406/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 407/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 408/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 409/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 410/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0293\n",
      "Epoch 411/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 412/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 413/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 414/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 415/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 416/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 417/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 418/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 419/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0292\n",
      "Epoch 420/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 421/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 422/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 423/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 424/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 425/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 426/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 427/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 428/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0293\n",
      "Epoch 429/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0292\n",
      "Epoch 430/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0292\n",
      "Epoch 431/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 432/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 433/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0292\n",
      "Epoch 434/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 435/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 436/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0292\n",
      "Epoch 437/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 438/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 439/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 440/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0293\n",
      "Epoch 441/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0292\n",
      "Epoch 442/500\n",
      "659/659 [==============================] - 8s 12ms/step - loss: 0.0292\n",
      "Epoch 443/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0292\n",
      "Epoch 444/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 445/500\n",
      "659/659 [==============================] - 6s 9ms/step - loss: 0.0293\n",
      "Epoch 446/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0293\n",
      "Epoch 447/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0292\n",
      "Epoch 448/500\n",
      "659/659 [==============================] - 5s 8ms/step - loss: 0.0292\n",
      "Epoch 449/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 450/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 451/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 452/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 453/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 454/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 455/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 456/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 457/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 458/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 459/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 460/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 461/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 462/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 463/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 464/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 465/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 466/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 467/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 468/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 469/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 470/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 471/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 472/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 473/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 474/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 475/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 476/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 477/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 478/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 479/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 480/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 481/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 482/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 483/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 484/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 485/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 486/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 487/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 488/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 489/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 490/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 491/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0294\n",
      "Epoch 492/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 493/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 494/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 495/500\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0292\n",
      "Epoch 496/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 497/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 498/500\n",
      "659/659 [==============================] - 5s 7ms/step - loss: 0.0292\n",
      "Epoch 499/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n",
      "Epoch 500/500\n",
      "659/659 [==============================] - 4s 7ms/step - loss: 0.0292\n"
     ]
    }
   ],
   "source": [
    "## Compiling and Training\n",
    "start_time = time.time()\n",
    "retrained_stage2.compile(optimizer='adam', loss='mae')\n",
    "retrained_stage2.fit(benign_data_total , benign_data_total , batch_size=256, epochs=500, shuffle=True)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd4f7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the retrained model\n",
    "retrained_stage2.save('retrained_stage2_hybrid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9ef1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the retrained model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "retrained_stage2 = load_model('retrained_stage2_hybrid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "947ba1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2039.2511141300201\n"
     ]
    }
   ],
   "source": [
    "time_taken = end_time - start_time\n",
    "print(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5910d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CICIDS2017 and CICIDS2018 Testing retrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88b398b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 3ms/step\n",
      "120/120 [==============================] - 0s 4ms/step\n",
      "120/120 [==============================] - 0s 2ms/step\n",
      "120/120 [==============================] - 0s 3ms/step\n",
      "120/120 [==============================] - 0s 2ms/step\n",
      "120/120 [==============================] - 0s 2ms/step\n",
      "716/716 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "inf_ = retrained_stage2.predict(infiltration_attack)\n",
    "port_ = retrained_stage2.predict(portscan_attack)\n",
    "dos_ = retrained_stage2.predict(dos_attack)\n",
    "ddos_ = retrained_stage2.predict(ddos_attack)\n",
    "web_ = retrained_stage2.predict(web_attack)\n",
    "brute_ = retrained_stage2.predict(bruteforce_attack)\n",
    "ben_ = retrained_stage2.predict(benign_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ace233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_byte_list = recon_metrices(benign_data,ben_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ad764f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_byte_avg 0.11650496069633351\n",
      "mae_byte_99_percentile 0.22918970822951318\n",
      "mae_byte_95_percentile 0.17450515541714123\n",
      "mae_byte_90_percentile 0.15900632962172317\n"
     ]
    }
   ],
   "source": [
    "mae_byte_avg = sum(mae_byte_list) / len(mae_byte_list)\n",
    "print('mae_byte_avg', mae_byte_avg)\n",
    "mae_byte_per_95 = np.percentile(mae_byte_list, 99)\n",
    "print('mae_byte_99_percentile', mae_byte_per_95)\n",
    "mae_byte_per_95 = np.percentile(mae_byte_list, 95)\n",
    "print('mae_byte_95_percentile', mae_byte_per_95)\n",
    "mae_byte_per_95 = np.percentile(mae_byte_list, 90)\n",
    "print('mae_byte_90_percentile', mae_byte_per_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f37b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7850c38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910/910 [==============================] - 2s 2ms/step\n",
      "910/910 [==============================] - 2s 2ms/step\n",
      "910/910 [==============================] - 2s 2ms/step\n",
      "910/910 [==============================] - 2s 2ms/step\n",
      "910/910 [==============================] - 2s 2ms/step\n",
      "4550/4550 [==============================] - 12s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "inf_2018 = retrained_stage2.predict(infiltration_attack_2018)\n",
    "dos_2018 = retrained_stage2.predict(dos_attack_2018)\n",
    "ddos_2018 = retrained_stage2.predict(ddos_attack_2018)\n",
    "web_2018 = retrained_stage2.predict(web_attack_2018)\n",
    "brute_2018 = retrained_stage2.predict(bruteforce_attack_2018)\n",
    "ben_2018 = retrained_stage2.predict(benign_data_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0f6f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_byte_list = recon_metrices(benign_data_2018,ben_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04feca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10956250558116212\n"
     ]
    }
   ],
   "source": [
    "## Classification\n",
    "count_99 = len([i for i in mae_byte_list if i > 0.22])\n",
    "print(count_99 / len(mae_byte_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543812c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4aace546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infiltration\n",
      "7089\n",
      "0.7565256216513258\n",
      "DoS\n",
      "1578\n",
      "0.9458029949168842\n",
      "DDoS\n",
      "3\n",
      "0.999896960329727\n",
      "Web\n",
      "1476\n",
      "0.9493062233823327\n",
      "Brute\n",
      "730\n",
      "0.9749278747080643\n",
      "Benign\n",
      "130481\n",
      "0.8962899868799759\n"
     ]
    }
   ],
   "source": [
    "print('Infiltration')\n",
    "cnt_inf, acc_inf = accuracy_calc(inf_2018)\n",
    "print(cnt_inf)\n",
    "print(acc_inf)\n",
    "print('DoS')\n",
    "cnt_dos, acc_dos = accuracy_calc(dos_2018)\n",
    "print(cnt_dos)\n",
    "print(acc_dos)\n",
    "print('DDoS')\n",
    "cnt_ddos, acc_ddos = accuracy_calc(ddos_2018)\n",
    "print(cnt_ddos)\n",
    "print(acc_ddos)\n",
    "print('Web')\n",
    "cnt_web, acc_web = accuracy_calc(web_2018)\n",
    "print(cnt_web)\n",
    "print(acc_web)\n",
    "print('Brute')\n",
    "cnt_brute, acc_brute = accuracy_calc(brute_2018)\n",
    "print(cnt_brute)\n",
    "print(acc_brute)\n",
    "print('Benign')\n",
    "cnt_ben, acc_ben = accuracy_calc(ben_2018)\n",
    "print(cnt_ben)\n",
    "print(1-acc_ben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CICIDS2017 Testing Retrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b219a3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 0s 4ms/step\n",
      "120/120 [==============================] - 0s 4ms/step\n",
      "120/120 [==============================] - 0s 4ms/step\n",
      "120/120 [==============================] - 0s 4ms/step\n",
      "716/716 [==============================] - 3s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "inf = retrained_stage1.predict(infiltration_attack)\n",
    "dos = retrained_stage1.predict(dos_attack)\n",
    "ddos = retrained_stage1.predict(ddos_attack)\n",
    "web = retrained_stage1.predict(web_attack)\n",
    "brute = retrained_stage1.predict(bruteforce_attack)\n",
    "ben = retrained_stage1.predict(benign_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5aed36ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infiltration\n",
      "3\n",
      "0.9992140424417082\n",
      "DoS\n",
      "170\n",
      "0.9554507337526206\n",
      "DDoS\n",
      "50\n",
      "0.9869007073618025\n",
      "Web\n",
      "99\n",
      "0.9740566037735849\n",
      "Brute\n",
      "52\n",
      "0.9863767356562746\n",
      "Benign\n",
      "22597\n",
      "0.986768558951965\n"
     ]
    }
   ],
   "source": [
    "print('Infiltration')\n",
    "cnt_inf, acc_inf = accuracy_calc(inf)\n",
    "print(cnt_inf)\n",
    "print(acc_inf)\n",
    "print('DoS')\n",
    "cnt_dos, acc_dos = accuracy_calc(dos)\n",
    "print(cnt_dos)\n",
    "print(acc_dos)\n",
    "print('DDoS')\n",
    "cnt_ddos, acc_ddos = accuracy_calc(ddos)\n",
    "print(cnt_ddos)\n",
    "print(acc_ddos)\n",
    "print('Web')\n",
    "cnt_web, acc_web = accuracy_calc(web)\n",
    "print(cnt_web)\n",
    "print(acc_web)\n",
    "print('Brute')\n",
    "cnt_brute, acc_brute = accuracy_calc(brute)\n",
    "print(cnt_brute)\n",
    "print(acc_brute)\n",
    "print('Benign')\n",
    "cnt_ben, acc_ben = accuracy_calc(ben)\n",
    "print(cnt_ben)\n",
    "print(1-acc_ben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0d5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db833da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f155d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
