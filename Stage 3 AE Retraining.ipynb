{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e50224e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras import Sequential,layers, losses, optimizers\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5fb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"all_group_train_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee8dc0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign          53432\n",
       "DoS              8906\n",
       "Web Attack       8906\n",
       "Infiltration     8905\n",
       "Port Scan        8905\n",
       "DDoS             8905\n",
       "Brute Force      8905\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d638bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"all_group_test_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aacaa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3817, 200)\n",
      "(3817, 200)\n",
      "(3817, 200)\n",
      "(3817, 200)\n",
      "(3816, 200)\n",
      "(3816, 200)\n",
      "(22900, 200)\n"
     ]
    }
   ],
   "source": [
    "infiltration_attack = df_test[df_test['Label'] == 'Infiltration'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(infiltration_attack.shape)\n",
    "portscan_attack = df_test[df_test['Label'] == 'Port Scan'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(portscan_attack.shape)\n",
    "ddos_attack = df_test[df_test['Label'] == 'DDoS'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(ddos_attack.shape)\n",
    "bruteforce_attack = df_test[df_test['Label'] == 'Brute Force'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(bruteforce_attack.shape)\n",
    "dos_attack = df_test[df_test['Label'] == 'DoS'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(dos_attack.shape)\n",
    "web_attack = df_test[df_test['Label'] == 'Web Attack'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(web_attack.shape)\n",
    "benign_data = df_test[df_test['Label'] == 'Benign'].drop(['Label_binary','Label'], axis=1).iloc[:,0:200]\n",
    "print(benign_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eee99bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_header_byte_2</th>\n",
       "      <th>ip_header_byte_3</th>\n",
       "      <th>ip_header_byte_4</th>\n",
       "      <th>ip_header_byte_5</th>\n",
       "      <th>ip_header_byte_6</th>\n",
       "      <th>ip_header_byte_7</th>\n",
       "      <th>ip_header_byte_8</th>\n",
       "      <th>ip_header_byte_10</th>\n",
       "      <th>ip_header_byte_11</th>\n",
       "      <th>tcp_header_byte_4</th>\n",
       "      <th>...</th>\n",
       "      <th>tcp_segment_data_byte_125</th>\n",
       "      <th>tcp_segment_data_byte_126</th>\n",
       "      <th>tcp_segment_data_byte_127</th>\n",
       "      <th>tcp_segment_data_byte_128</th>\n",
       "      <th>tcp_segment_data_byte_129</th>\n",
       "      <th>tcp_segment_data_byte_130</th>\n",
       "      <th>tcp_segment_data_byte_131</th>\n",
       "      <th>tcp_segment_data_byte_132</th>\n",
       "      <th>tcp_segment_data_byte_133</th>\n",
       "      <th>tcp_segment_data_byte_134</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45759</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45761</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45768</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45781</th>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.180392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45790</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.486275</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.125490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3817 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip_header_byte_2  ip_header_byte_3  ip_header_byte_4  ip_header_byte_5  \\\n",
       "5              0.007843          0.109804          0.054902          0.980392   \n",
       "14             0.003922          0.717647          0.286275          0.760784   \n",
       "16             0.003922          0.835294          0.172549          0.192157   \n",
       "19             0.007843          0.109804          0.054902          0.494118   \n",
       "28             0.007843          0.109804          0.145098          0.443137   \n",
       "...                 ...               ...               ...               ...   \n",
       "45759          0.003922          0.133333          0.215686          0.541176   \n",
       "45761          0.007843          0.686275          0.180392          0.145098   \n",
       "45768          0.000000          0.270588          0.086275          0.329412   \n",
       "45781          0.011765          0.168627          0.462745          0.356863   \n",
       "45790          0.007843          0.109804          0.486275          0.407843   \n",
       "\n",
       "       ip_header_byte_6  ip_header_byte_7  ip_header_byte_8  \\\n",
       "5               0.25098               0.0          0.501961   \n",
       "14              0.25098               0.0          0.501961   \n",
       "16              0.25098               0.0          0.501961   \n",
       "19              0.25098               0.0          0.501961   \n",
       "28              0.25098               0.0          0.501961   \n",
       "...                 ...               ...               ...   \n",
       "45759           0.25098               0.0          0.501961   \n",
       "45761           0.25098               0.0          0.501961   \n",
       "45768           0.25098               0.0          0.501961   \n",
       "45781           0.25098               0.0          0.501961   \n",
       "45790           0.25098               0.0          0.501961   \n",
       "\n",
       "       ip_header_byte_10  ip_header_byte_11  tcp_header_byte_4  ...  \\\n",
       "5               0.674510           0.223529           0.196078  ...   \n",
       "14              0.443137           0.839216           0.929412  ...   \n",
       "16              0.560784           0.286275           0.196078  ...   \n",
       "19              0.674510           0.709804           0.196078  ...   \n",
       "28              0.584314           0.760784           0.929412  ...   \n",
       "...                  ...                ...                ...  ...   \n",
       "45759           0.517647           0.639216           0.196078  ...   \n",
       "45761           0.549020           0.482353           0.196078  ...   \n",
       "45768           0.650980           0.713725           0.196078  ...   \n",
       "45781           0.262745           0.788235           0.192157  ...   \n",
       "45790           0.243137           0.796078           0.196078  ...   \n",
       "\n",
       "       tcp_segment_data_byte_125  tcp_segment_data_byte_126  \\\n",
       "5                       0.152941                   0.431373   \n",
       "14                      0.152941                   0.431373   \n",
       "16                      0.050980                   0.039216   \n",
       "19                      0.152941                   0.431373   \n",
       "28                      0.152941                   0.431373   \n",
       "...                          ...                        ...   \n",
       "45759                   0.050980                   0.039216   \n",
       "45761                   0.152941                   0.431373   \n",
       "45768                   0.000000                   0.000000   \n",
       "45781                   0.450980                   0.298039   \n",
       "45790                   0.152941                   0.431373   \n",
       "\n",
       "       tcp_segment_data_byte_127  tcp_segment_data_byte_128  \\\n",
       "5                       0.427451                   0.380392   \n",
       "14                      0.427451                   0.380392   \n",
       "16                      0.262745                   0.227451   \n",
       "19                      0.427451                   0.380392   \n",
       "28                      0.427451                   0.380392   \n",
       "...                          ...                        ...   \n",
       "45759                   0.262745                   0.227451   \n",
       "45761                   0.427451                   0.380392   \n",
       "45768                   0.000000                   0.000000   \n",
       "45781                   0.125490                   0.176471   \n",
       "45790                   0.427451                   0.380392   \n",
       "\n",
       "       tcp_segment_data_byte_129  tcp_segment_data_byte_130  \\\n",
       "5                       0.439216                   0.152941   \n",
       "14                      0.439216                   0.152941   \n",
       "16                      0.360784                   0.243137   \n",
       "19                      0.439216                   0.152941   \n",
       "28                      0.439216                   0.152941   \n",
       "...                          ...                        ...   \n",
       "45759                   0.360784                   0.243137   \n",
       "45761                   0.439216                   0.152941   \n",
       "45768                   0.000000                   0.000000   \n",
       "45781                   0.431373                   0.125490   \n",
       "45790                   0.439216                   0.152941   \n",
       "\n",
       "       tcp_segment_data_byte_131  tcp_segment_data_byte_132  \\\n",
       "5                       0.125490                   0.411765   \n",
       "14                      0.125490                   0.411765   \n",
       "16                      0.431373                   0.427451   \n",
       "19                      0.125490                   0.411765   \n",
       "28                      0.125490                   0.411765   \n",
       "...                          ...                        ...   \n",
       "45759                   0.431373                   0.427451   \n",
       "45761                   0.125490                   0.411765   \n",
       "45768                   0.000000                   0.000000   \n",
       "45781                   0.192157                   0.223529   \n",
       "45790                   0.125490                   0.411765   \n",
       "\n",
       "       tcp_segment_data_byte_133  tcp_segment_data_byte_134  \n",
       "5                       0.450980                   0.125490  \n",
       "14                      0.450980                   0.125490  \n",
       "16                      0.380392                   0.439216  \n",
       "19                      0.450980                   0.125490  \n",
       "28                      0.450980                   0.125490  \n",
       "...                          ...                        ...  \n",
       "45759                   0.380392                   0.439216  \n",
       "45761                   0.450980                   0.125490  \n",
       "45768                   0.000000                   0.000000  \n",
       "45781                   0.196078                   0.180392  \n",
       "45790                   0.450980                   0.125490  \n",
       "\n",
       "[3817 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infiltration_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b58a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_2018 = pd.read_csv(\"all_group_train_normalized_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5e3271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_2018 = df_test_2018.sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b4049c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_header_byte_2</th>\n",
       "      <th>ip_header_byte_3</th>\n",
       "      <th>ip_header_byte_4</th>\n",
       "      <th>ip_header_byte_5</th>\n",
       "      <th>ip_header_byte_6</th>\n",
       "      <th>ip_header_byte_7</th>\n",
       "      <th>ip_header_byte_8</th>\n",
       "      <th>ip_header_byte_10</th>\n",
       "      <th>ip_header_byte_11</th>\n",
       "      <th>tcp_header_byte_4</th>\n",
       "      <th>...</th>\n",
       "      <th>tcp_segment_data_byte_1452</th>\n",
       "      <th>tcp_segment_data_byte_1453</th>\n",
       "      <th>tcp_segment_data_byte_1454</th>\n",
       "      <th>tcp_segment_data_byte_1455</th>\n",
       "      <th>tcp_segment_data_byte_1456</th>\n",
       "      <th>tcp_segment_data_byte_1457</th>\n",
       "      <th>tcp_segment_data_byte_1458</th>\n",
       "      <th>tcp_segment_data_byte_1459</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Web Attack</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Infiltration</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291153</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291154</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291155</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291156</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ddos</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291157</th>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.25098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>Web Attack</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291158 rows × 1527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ip_header_byte_2  ip_header_byte_3  ip_header_byte_4  \\\n",
       "0               0.000000          0.650980          0.262745   \n",
       "1               0.000000          0.203922          0.090196   \n",
       "2               0.000000          0.156863          0.003922   \n",
       "3               0.000000          0.337255          0.384314   \n",
       "4               0.000000          0.352941          0.094118   \n",
       "...                  ...               ...               ...   \n",
       "291153          0.000000          0.156863          0.007843   \n",
       "291154          0.000000          0.156863          0.435294   \n",
       "291155          0.000000          0.203922          0.090196   \n",
       "291156          0.000000          0.156863          0.149020   \n",
       "291157          0.027451          0.709804          0.658824   \n",
       "\n",
       "        ip_header_byte_5  ip_header_byte_6  ip_header_byte_7  \\\n",
       "0               0.298039           0.25098               0.0   \n",
       "1               0.878431           0.25098               0.0   \n",
       "2               0.537255           0.25098               0.0   \n",
       "3               0.313725           0.25098               0.0   \n",
       "4               0.568627           0.25098               0.0   \n",
       "...                  ...               ...               ...   \n",
       "291153          0.325490           0.25098               0.0   \n",
       "291154          0.141176           0.25098               0.0   \n",
       "291155          0.803922           0.25098               0.0   \n",
       "291156          0.603922           0.25098               0.0   \n",
       "291157          0.705882           0.25098               0.0   \n",
       "\n",
       "        ip_header_byte_8  ip_header_byte_10  ip_header_byte_11  \\\n",
       "0               0.250980           0.941176           0.262745   \n",
       "1               0.250980           0.639216           0.921569   \n",
       "2               0.498039           0.509804           0.960784   \n",
       "3               0.501961           0.176471           0.552941   \n",
       "4               0.427451           0.552941           0.286275   \n",
       "...                  ...                ...                ...   \n",
       "291153          0.501961           0.109804           0.160784   \n",
       "291154          0.501961           0.686275           0.345098   \n",
       "291155          0.501961           0.125490           0.768627   \n",
       "291156          0.498039           0.921569           0.203922   \n",
       "291157          0.250980           0.074510           0.239216   \n",
       "\n",
       "        tcp_header_byte_4  ...  tcp_segment_data_byte_1452  \\\n",
       "0                0.529412  ...                         0.0   \n",
       "1                0.615686  ...                         0.0   \n",
       "2                0.168627  ...                         0.0   \n",
       "3                0.243137  ...                         0.0   \n",
       "4                0.156863  ...                         0.0   \n",
       "...                   ...  ...                         ...   \n",
       "291153           0.356863  ...                         0.0   \n",
       "291154           0.858824  ...                         0.0   \n",
       "291155           0.184314  ...                         0.0   \n",
       "291156           0.780392  ...                         0.0   \n",
       "291157           0.301961  ...                         0.6   \n",
       "\n",
       "        tcp_segment_data_byte_1453  tcp_segment_data_byte_1454  \\\n",
       "0                         0.000000                    0.000000   \n",
       "1                         0.000000                    0.000000   \n",
       "2                         0.000000                    0.000000   \n",
       "3                         0.000000                    0.000000   \n",
       "4                         0.000000                    0.000000   \n",
       "...                            ...                         ...   \n",
       "291153                    0.000000                    0.000000   \n",
       "291154                    0.000000                    0.000000   \n",
       "291155                    0.000000                    0.000000   \n",
       "291156                    0.000000                    0.000000   \n",
       "291157                    0.062745                    0.070588   \n",
       "\n",
       "        tcp_segment_data_byte_1455  tcp_segment_data_byte_1456  \\\n",
       "0                         0.000000                    0.000000   \n",
       "1                         0.000000                    0.000000   \n",
       "2                         0.000000                    0.000000   \n",
       "3                         0.000000                    0.000000   \n",
       "4                         0.000000                    0.000000   \n",
       "...                            ...                         ...   \n",
       "291153                    0.000000                    0.000000   \n",
       "291154                    0.000000                    0.000000   \n",
       "291155                    0.000000                    0.000000   \n",
       "291156                    0.000000                    0.000000   \n",
       "291157                    0.678431                    0.035294   \n",
       "\n",
       "        tcp_segment_data_byte_1457  tcp_segment_data_byte_1458  \\\n",
       "0                         0.000000                    0.000000   \n",
       "1                         0.000000                    0.000000   \n",
       "2                         0.000000                    0.000000   \n",
       "3                         0.000000                    0.000000   \n",
       "4                         0.000000                    0.000000   \n",
       "...                            ...                         ...   \n",
       "291153                    0.000000                    0.000000   \n",
       "291154                    0.000000                    0.000000   \n",
       "291155                    0.000000                    0.000000   \n",
       "291156                    0.000000                    0.000000   \n",
       "291157                    0.490196                    0.564706   \n",
       "\n",
       "        tcp_segment_data_byte_1459         Label  Label_binary  \n",
       "0                         0.000000        Benign        Benign  \n",
       "1                         0.000000        Benign        Benign  \n",
       "2                         0.000000    Web Attack     Malicious  \n",
       "3                         0.000000        Benign        Benign  \n",
       "4                         0.000000  Infiltration     Malicious  \n",
       "...                            ...           ...           ...  \n",
       "291153                    0.000000        Benign        Benign  \n",
       "291154                    0.000000        Benign        Benign  \n",
       "291155                    0.000000        Benign        Benign  \n",
       "291156                    0.000000          ddos     Malicious  \n",
       "291157                    0.709804    Web Attack     Malicious  \n",
       "\n",
       "[291158 rows x 1527 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e567e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2018 = df_test_2018.iloc[:,0:1525]\n",
    "Y_train_2018 = df_test_2018.iloc[:,1526:1527]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac7d864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2017 = df_test.iloc[:,0:1525]\n",
    "Y_train_2017 = df_test.iloc[:,1526:1527]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a88af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_2017.loc[Y_train_2017['Label_binary'] == 'Benign', 'Label_binary'] = 0\n",
    "Y_train_2017.loc[Y_train_2017['Label_binary'] == 'Malicious', 'Label_binary'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a817f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_2018.loc[Y_train_2018['Label_binary'] == 'Benign', 'Label_binary'] = 0\n",
    "Y_train_2018.loc[Y_train_2018['Label_binary'] == 'Malicious', 'Label_binary'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89982815",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_total = pd.concat([X_train_2017,X_train_2018])\n",
    "Y_train_total = pd.concat([Y_train_2017,Y_train_2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef3e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = X_train_total.values.astype('float32')\n",
    "Y_train_ = Y_train_total.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c320991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a6a8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29116, 500)\n",
      "(0, 500)\n",
      "(29115, 500)\n",
      "(29116, 500)\n",
      "(29116, 500)\n",
      "(29116, 500)\n",
      "(145579, 500)\n"
     ]
    }
   ],
   "source": [
    "infiltration_attack_2018 = df_test_2018[df_test_2018['Label'] == 'Infiltration'].drop(['Label_binary','Label'], axis=1).iloc[:,0:500]\n",
    "print(infiltration_attack_2018.shape)\n",
    "portscan_attack_2018 = df_test_2018[df_test_2018['Label'] == 'Port Scan'].drop(['Label_binary','Label'], axis=1).iloc[:,0:500]\n",
    "print(portscan_attack_2018.shape)\n",
    "ddos_attack_2018 = df_test_2018[df_test_2018['Label'] == 'ddos'].drop(['Label_binary','Label'], axis=1).iloc[:,0:500]\n",
    "print(ddos_attack_2018.shape)\n",
    "bruteforce_attack_2018 = df_test_2018[df_test_2018['Label'] == 'Brute Force'].drop(['Label_binary','Label'], axis=1).iloc[:,0:500]\n",
    "print(bruteforce_attack_2018.shape)\n",
    "dos_attack_2018 = df_test_2018[df_test_2018['Label'] == 'DoS'].drop(['Label_binary','Label'], axis=1).iloc[:,0:500]\n",
    "print(dos_attack_2018.shape)\n",
    "web_attack_2018 = df_test_2018[df_test_2018['Label'] == 'Web Attack'].drop(['Label_binary','Label'], axis=1).iloc[:,0:500]\n",
    "print(web_attack_2018.shape)\n",
    "benign_data_2018 = df_test_2018[df_test_2018['Label'] == 'Benign'].drop(['Label_binary','Label'], axis=1).iloc[:,0:500]\n",
    "print(benign_data_2018.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "690600b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_data_total = pd.concat([benign_data, benign_data_2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77495139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train.loc[Y_train['Label_binary'] == 'Benign', 'Label_binary'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2638e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage3_AE = tf.keras.models.load_model('Stage3_AE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc9a28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_metrices(data, reconstructed_data):\n",
    "\n",
    "    maes = np.absolute(data.values - reconstructed_data)\n",
    "    \n",
    "    for j in range(len(maes)):\n",
    "        m = maes[j]\n",
    "        d = data.values[j]\n",
    "        r = reconstructed_data[j]\n",
    "        for el in range(len(m)):\n",
    "            if r[el] == 0 or d[el] == 0:\n",
    "                m[el] = 0\n",
    " \n",
    "            \n",
    "    mae_byte_list = []\n",
    "    ip_mae_list = []\n",
    "    tcp_header_mae_list = []\n",
    "    tcp_options_mae_list = []\n",
    "    tcp_segment_mae_list = []\n",
    "    i=0\n",
    "    for mae in maes:\n",
    "#         print(np.count_nonzero(reconstructed_data[i]))\n",
    "#         print(np.count_nonzero(data.values[i]))\n",
    "#         print(np.max(np.count_nonzero(reconstructed_data[i]),np.count_nonzero(data.values[i])))\n",
    "        mae_byte = sum(mae) / np.count_nonzero(mae)\n",
    "        mae_byte_list.append(mae_byte)\n",
    "        i += 1\n",
    "    return mae_byte_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3527b235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910/910 [==============================] - 5s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "inf = stage3_AE.predict(infiltration_attack_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b24a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_byte_list = recon_metrices(infiltration_attack_2018,inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "727837e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8673238082154142\n"
     ]
    }
   ],
   "source": [
    "## Classification\n",
    "count_99 = len([i for i in mae_byte_list if i > 0.09])\n",
    "print(count_99 / len(mae_byte_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96738787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 400)               200400    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 400)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               120300    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 250)               75250     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 125)               31375     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 62)                7812      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 125)               7875      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 250)               31500     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 300)               75300     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 400)               120400    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 400)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 500)               200500    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,121,212\n",
      "Trainable params: 1,121,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stage3_AE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b19ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retraining with CICIDS 2018 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24d36555",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_layers = [5,6,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52c383b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer5_ind = [h for h in range(0,250,3)]\n",
    "layer6_ind = [h for h in range(0,125,3)]\n",
    "layer8_ind = [h for h in range(0,125,3)]\n",
    "layer9_ind = [h for h in range(0,250,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a13adec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrained_stage3 = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22907efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(stage3_AE.layers):\n",
    "    if i not in mod_layers:\n",
    "        layer.trainable = False\n",
    "        retrained_stage3.add(layer)\n",
    "    else:\n",
    "        retrained_stage3.add(layer)\n",
    "        if i == 5:\n",
    "            for ind in range(0,250):\n",
    "                if ind in layer5_ind:\n",
    "                    retrained_stage3.layers[-1].kernel[ind]._trainable = False\n",
    "        if i == 6:\n",
    "            for ind in range(0,125):\n",
    "                if ind in layer6_ind:\n",
    "                    retrained_stage3.layers[-1].kernel[ind]._trainable = False\n",
    "                    \n",
    "        if i == 8:\n",
    "            for ind in range(0,62):\n",
    "                if ind in layer8_ind:\n",
    "                    retrained_stage3.layers[-1].kernel[ind]._trainable = False\n",
    "        \n",
    "        if i == 9:\n",
    "            for ind in range(0,125):\n",
    "                if ind in layer9_ind:\n",
    "                    retrained_stage3.layers[-1].kernel[ind]._trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e0370c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 400)               200400    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 400)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               120300    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 250)               75250     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 125)               31375     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 62)                7812      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 125)               7875      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 250)               31500     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 300)               75300     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 400)               120400    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 400)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 500)               200500    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,121,212\n",
      "Trainable params: 146,000\n",
      "Non-trainable params: 975,212\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "retrained_stage3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "944609ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv = pd.read_csv(\"adv_examples_all_allDNN_bigger.csv\")\n",
    "df_adv_syn = pd.read_csv(\"Adv_all_DNN_incremental.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d81ef954",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv_syn= df_adv_syn.loc[:, ~df_adv_syn.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "006a3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_train = df_adv.iloc[:,:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75f4c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_syn = df_adv_syn.iloc[:,:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26a8c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_total = pd.concat([adv_train,adv_syn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1e14323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "66/66 [==============================] - 2s 14ms/step - loss: 0.0084\n",
      "Epoch 2/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0073\n",
      "Epoch 3/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0070\n",
      "Epoch 4/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0068\n",
      "Epoch 5/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0066\n",
      "Epoch 6/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0065\n",
      "Epoch 7/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0064\n",
      "Epoch 8/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0063\n",
      "Epoch 9/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0062\n",
      "Epoch 10/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0061\n",
      "Epoch 11/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0060\n",
      "Epoch 12/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0059\n",
      "Epoch 13/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0059\n",
      "Epoch 14/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0059\n",
      "Epoch 15/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0059\n",
      "Epoch 16/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0058\n",
      "Epoch 17/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0058\n",
      "Epoch 18/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0058\n",
      "Epoch 19/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0057\n",
      "Epoch 20/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0057\n",
      "Epoch 21/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0057\n",
      "Epoch 22/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0056\n",
      "Epoch 23/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0056\n",
      "Epoch 24/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0056\n",
      "Epoch 25/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0056\n",
      "Epoch 26/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0055\n",
      "Epoch 27/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0055\n",
      "Epoch 28/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0055\n",
      "Epoch 29/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0055\n",
      "Epoch 30/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0054\n",
      "Epoch 31/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0054\n",
      "Epoch 32/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0055\n",
      "Epoch 33/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0054\n",
      "Epoch 34/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0054\n",
      "Epoch 35/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0054\n",
      "Epoch 36/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0054\n",
      "Epoch 37/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0054\n",
      "Epoch 38/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0054\n",
      "Epoch 39/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0054\n",
      "Epoch 40/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0054\n",
      "Epoch 41/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0054\n",
      "Epoch 42/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0053\n",
      "Epoch 43/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0053\n",
      "Epoch 44/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0053\n",
      "Epoch 45/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0053\n",
      "Epoch 46/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0053\n",
      "Epoch 47/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0053\n",
      "Epoch 48/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0053\n",
      "Epoch 49/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0052\n",
      "Epoch 50/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0053\n",
      "Epoch 51/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0053\n",
      "Epoch 52/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0052\n",
      "Epoch 53/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0052\n",
      "Epoch 54/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0052\n",
      "Epoch 55/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0053\n",
      "Epoch 56/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0052\n",
      "Epoch 57/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0052\n",
      "Epoch 58/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0052\n",
      "Epoch 59/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0052\n",
      "Epoch 60/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0052\n",
      "Epoch 61/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0052\n",
      "Epoch 62/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0052\n",
      "Epoch 63/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0052\n",
      "Epoch 64/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0052\n",
      "Epoch 65/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0052\n",
      "Epoch 66/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0052\n",
      "Epoch 67/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0052\n",
      "Epoch 68/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0052\n",
      "Epoch 69/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 70/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0052\n",
      "Epoch 71/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 72/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 73/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0052\n",
      "Epoch 74/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 75/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 76/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 77/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 78/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 79/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 80/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 81/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 82/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 83/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 84/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 85/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 86/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 87/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 88/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 89/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0051\n",
      "Epoch 90/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 91/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 92/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0051\n",
      "Epoch 93/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 94/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 95/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 96/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 97/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 98/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 99/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 100/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 101/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 102/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 103/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 104/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 105/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 106/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 107/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 108/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 109/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 110/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 111/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 112/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 113/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 114/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 115/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 116/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 117/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 118/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0051\n",
      "Epoch 119/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 120/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 121/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 122/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0050\n",
      "Epoch 123/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 124/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 125/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 126/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 127/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 128/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 129/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 130/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 131/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 132/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 133/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 134/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 135/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 136/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 137/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 138/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 139/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 140/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 141/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 142/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 143/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 144/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 145/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 146/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 147/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 148/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 149/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 150/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 151/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 152/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 153/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 154/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 155/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 156/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 157/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 158/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 159/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 160/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 161/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 162/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 163/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 164/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 165/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 166/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 167/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 168/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 169/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 170/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0050\n",
      "Epoch 171/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 172/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 173/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 174/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 175/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 176/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 177/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 178/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 179/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 180/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 181/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 182/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 183/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 184/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 185/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 186/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 187/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 188/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 189/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 190/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 191/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 192/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 193/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 194/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 195/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 196/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 197/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 198/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 199/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 200/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 201/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 202/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0048\n",
      "Epoch 203/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0048\n",
      "Epoch 204/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 205/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0048\n",
      "Epoch 206/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 207/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 208/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 209/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 210/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 211/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 212/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 213/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 214/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0048\n",
      "Epoch 215/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 216/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0048\n",
      "Epoch 217/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 218/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 219/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 220/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0048\n",
      "Epoch 221/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0048\n",
      "Epoch 222/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 223/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0049\n",
      "Epoch 224/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 225/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 226/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0049\n",
      "Epoch 227/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 228/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0048\n",
      "Epoch 229/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0048\n",
      "Epoch 230/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0048\n",
      "Epoch 231/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0048\n",
      "Epoch 232/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0048\n",
      "Epoch 233/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0048\n",
      "Epoch 234/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0048\n",
      "Epoch 235/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0048\n",
      "Epoch 236/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0048\n",
      "Epoch 237/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0049\n",
      "Epoch 238/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0049\n",
      "Epoch 239/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0048\n",
      "Epoch 240/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0048\n",
      "Epoch 241/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0048\n",
      "Epoch 242/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0048\n",
      "Epoch 243/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0048\n",
      "Epoch 244/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0048\n",
      "Epoch 245/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0048\n",
      "Epoch 246/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0048\n",
      "Epoch 247/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0048\n",
      "Epoch 248/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0048\n",
      "Epoch 249/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0048\n",
      "Epoch 250/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0047\n",
      "Epoch 251/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0048\n",
      "Epoch 252/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0048\n",
      "Epoch 253/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0048\n",
      "Epoch 254/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0048\n",
      "Epoch 255/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0048\n",
      "Epoch 256/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0048\n",
      "Epoch 257/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0047\n",
      "Epoch 258/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0047\n",
      "Epoch 259/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0048\n",
      "Epoch 260/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 261/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0049\n",
      "Epoch 262/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0048\n",
      "Epoch 263/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0048\n",
      "Epoch 264/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 265/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0048\n",
      "Epoch 266/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0047\n",
      "Epoch 267/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0047\n",
      "Epoch 268/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0047\n",
      "Epoch 269/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0048\n",
      "Epoch 270/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0048\n",
      "Epoch 271/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0047\n",
      "Epoch 272/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0048\n",
      "Epoch 273/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0047\n",
      "Epoch 274/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0048\n",
      "Epoch 275/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 276/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 277/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0048\n",
      "Epoch 278/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0047\n",
      "Epoch 279/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 280/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 281/500\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.0048\n",
      "Epoch 282/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0048\n",
      "Epoch 283/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0048\n",
      "Epoch 284/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 285/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0047\n",
      "Epoch 286/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0047\n",
      "Epoch 287/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 288/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0047\n",
      "Epoch 289/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 290/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 291/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 292/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 293/500\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.0047\n",
      "Epoch 294/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0047\n",
      "Epoch 295/500\n",
      "66/66 [==============================] - 2s 24ms/step - loss: 0.0047\n",
      "Epoch 296/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0047\n",
      "Epoch 298/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0047\n",
      "Epoch 299/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0047\n",
      "Epoch 300/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0047\n",
      "Epoch 301/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 302/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0047\n",
      "Epoch 303/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 304/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 305/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0047\n",
      "Epoch 306/500\n",
      "66/66 [==============================] - 2s 24ms/step - loss: 0.0047\n",
      "Epoch 307/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0047\n",
      "Epoch 308/500\n",
      "66/66 [==============================] - 2s 24ms/step - loss: 0.0047\n",
      "Epoch 309/500\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.0047\n",
      "Epoch 310/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0048\n",
      "Epoch 311/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0047\n",
      "Epoch 312/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0047\n",
      "Epoch 313/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0047\n",
      "Epoch 314/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0047\n",
      "Epoch 315/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0047\n",
      "Epoch 316/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0047\n",
      "Epoch 317/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0047\n",
      "Epoch 318/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0047\n",
      "Epoch 319/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 320/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0048\n",
      "Epoch 321/500\n",
      "66/66 [==============================] - 2s 26ms/step - loss: 0.0047\n",
      "Epoch 322/500\n",
      "66/66 [==============================] - 2s 25ms/step - loss: 0.0047\n",
      "Epoch 323/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0047\n",
      "Epoch 324/500\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.0047\n",
      "Epoch 325/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 326/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0047\n",
      "Epoch 327/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0047\n",
      "Epoch 328/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 329/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 330/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0046\n",
      "Epoch 331/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0047\n",
      "Epoch 332/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0047\n",
      "Epoch 333/500\n",
      "66/66 [==============================] - 2s 25ms/step - loss: 0.0047\n",
      "Epoch 334/500\n",
      "66/66 [==============================] - 2s 23ms/step - loss: 0.0047\n",
      "Epoch 335/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 336/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 337/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0047\n",
      "Epoch 338/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0047\n",
      "Epoch 339/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 340/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0046\n",
      "Epoch 341/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0046\n",
      "Epoch 342/500\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.0047\n",
      "Epoch 343/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 344/500\n",
      "66/66 [==============================] - 2s 23ms/step - loss: 0.0047\n",
      "Epoch 345/500\n",
      "66/66 [==============================] - 2s 24ms/step - loss: 0.0047\n",
      "Epoch 346/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 347/500\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.0047\n",
      "Epoch 348/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0046\n",
      "Epoch 349/500\n",
      "66/66 [==============================] - 2s 25ms/step - loss: 0.0047\n",
      "Epoch 350/500\n",
      "66/66 [==============================] - 2s 29ms/step - loss: 0.0047\n",
      "Epoch 351/500\n",
      "66/66 [==============================] - 2s 26ms/step - loss: 0.0047\n",
      "Epoch 352/500\n",
      "66/66 [==============================] - 2s 26ms/step - loss: 0.0047\n",
      "Epoch 353/500\n",
      "66/66 [==============================] - 2s 27ms/step - loss: 0.0047\n",
      "Epoch 354/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0046\n",
      "Epoch 355/500\n",
      "66/66 [==============================] - 2s 24ms/step - loss: 0.0046\n",
      "Epoch 356/500\n",
      "66/66 [==============================] - 2s 24ms/step - loss: 0.0047\n",
      "Epoch 357/500\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.0047\n",
      "Epoch 358/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0047\n",
      "Epoch 359/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 360/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0046\n",
      "Epoch 361/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 362/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0047\n",
      "Epoch 363/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0047\n",
      "Epoch 364/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0047\n",
      "Epoch 365/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0047\n",
      "Epoch 366/500\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.0047\n",
      "Epoch 367/500\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 0.0046\n",
      "Epoch 368/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0046\n",
      "Epoch 369/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0046\n",
      "Epoch 370/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 371/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0047\n",
      "Epoch 372/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0047\n",
      "Epoch 373/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0047\n",
      "Epoch 374/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0047\n",
      "Epoch 375/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 376/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 377/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0046\n",
      "Epoch 378/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 379/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 380/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0046\n",
      "Epoch 381/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0046\n",
      "Epoch 382/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0047\n",
      "Epoch 383/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 384/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 385/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0047\n",
      "Epoch 386/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0047\n",
      "Epoch 387/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 388/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 389/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 390/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 391/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0046\n",
      "Epoch 392/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0047\n",
      "Epoch 393/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 394/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 395/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0046\n",
      "Epoch 396/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 397/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 398/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0047\n",
      "Epoch 399/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0047\n",
      "Epoch 400/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 401/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 402/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 403/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0046\n",
      "Epoch 404/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 405/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 406/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0046\n",
      "Epoch 407/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 408/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0046\n",
      "Epoch 409/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 410/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 411/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 412/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 413/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 414/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 415/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 416/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 417/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0047\n",
      "Epoch 418/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 419/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0047\n",
      "Epoch 420/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 421/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0046\n",
      "Epoch 422/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 423/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0046\n",
      "Epoch 424/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 425/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 426/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0046\n",
      "Epoch 427/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0046\n",
      "Epoch 428/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0046\n",
      "Epoch 429/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 430/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 431/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 432/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 433/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 434/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 435/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 436/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0046\n",
      "Epoch 437/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 438/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0046\n",
      "Epoch 439/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 440/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0046\n",
      "Epoch 441/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 442/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0046\n",
      "Epoch 443/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 444/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 445/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 446/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 447/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 448/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 449/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 450/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 451/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0045\n",
      "Epoch 452/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0046\n",
      "Epoch 453/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 454/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0046\n",
      "Epoch 455/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 456/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 457/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 458/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 459/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 460/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0046\n",
      "Epoch 461/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 462/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 463/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0047\n",
      "Epoch 464/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 465/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 466/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 467/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 468/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 469/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 470/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 471/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 472/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 473/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 474/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 475/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 476/500\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 477/500\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.0046\n",
      "Epoch 478/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 479/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 480/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 481/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0047\n",
      "Epoch 482/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0045\n",
      "Epoch 483/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0045\n",
      "Epoch 484/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 485/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 486/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 487/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 488/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 489/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0045\n",
      "Epoch 490/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0045\n",
      "Epoch 491/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0046\n",
      "Epoch 492/500\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 0.0046\n",
      "Epoch 493/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 494/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0046\n",
      "Epoch 495/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 496/500\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0046\n",
      "Epoch 497/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 498/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n",
      "Epoch 499/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.0046\n",
      "Epoch 500/500\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_stage3.compile(optimizer='adam', loss='mae')\n",
    "retrained_stage3.fit(adv_total , adv_total , batch_size=256, epochs=500, shuffle=True)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd4f7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrained_stage3.save('retrained_stage3_neuronfreeze.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a029d722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "adv_test = retrained_stage3.predict(adv_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "947ba1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499.1160912513733\n"
     ]
    }
   ],
   "source": [
    "time_taken = end_time - start_time\n",
    "print(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6fcc797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_byte_list = recon_metrices(adv_syn,adv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8c59e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_byte_avg 0.02709251992947739\n",
      "mae_byte_99_percentile 0.1551133202528618\n",
      "mae_byte_95_percentile 0.10022516703973731\n",
      "mae_byte_90_percentile 0.0610183094324957\n"
     ]
    }
   ],
   "source": [
    "mae_byte_avg = sum(mae_byte_list) / len(mae_byte_list)\n",
    "print('mae_byte_avg', mae_byte_avg)\n",
    "mae_byte_per_95 = np.percentile(mae_byte_list, 99)\n",
    "print('mae_byte_99_percentile', mae_byte_per_95)\n",
    "mae_byte_per_95 = np.percentile(mae_byte_list, 95)\n",
    "print('mae_byte_95_percentile', mae_byte_per_95)\n",
    "mae_byte_per_95 = np.percentile(mae_byte_list, 90)\n",
    "print('mae_byte_90_percentile', mae_byte_per_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b779a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5910d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CICIDS2017 and CICIDS2018 Testing retrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_ = retrained_stage2.predict(infiltration_attack)\n",
    "port_ = retrained_stage2.predict(portscan_attack)\n",
    "dos_ = retrained_stage2.predict(dos_attack)\n",
    "ddos_ = retrained_stage2.predict(ddos_attack)\n",
    "web_ = retrained_stage2.predict(web_attack)\n",
    "brute_ = retrained_stage2.predict(bruteforce_attack)\n",
    "ben_ = retrained_stage2.predict(benign_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baac315",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_byte_list = recon_metrices(benign_data,ben_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_byte_avg = sum(mae_byte_list) / len(mae_byte_list)\n",
    "print('mae_byte_avg', mae_byte_avg)\n",
    "mae_byte_per_95 = np.percentile(mae_byte_list, 99)\n",
    "print('mae_byte_99_percentile', mae_byte_per_95)\n",
    "mae_byte_per_95 = np.percentile(mae_byte_list, 95)\n",
    "print('mae_byte_95_percentile', mae_byte_per_95)\n",
    "mae_byte_per_95 = np.percentile(mae_byte_list, 90)\n",
    "print('mae_byte_90_percentile', mae_byte_per_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afbdec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7850c38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910/910 [==============================] - 3s 3ms/step\n",
      "910/910 [==============================] - 3s 3ms/step\n",
      "910/910 [==============================] - 3s 3ms/step\n",
      "910/910 [==============================] - 3s 3ms/step\n",
      "910/910 [==============================] - 3s 3ms/step\n",
      "4550/4550 [==============================] - 17s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "inf_2018 = retrained_stage3.predict(infiltration_attack_2018)\n",
    "dos_2018 = retrained_stage3.predict(dos_attack_2018)\n",
    "ddos_2018 = retrained_stage3.predict(ddos_attack_2018)\n",
    "web_2018 = retrained_stage3.predict(web_attack_2018)\n",
    "brute_2018 = retrained_stage3.predict(bruteforce_attack_2018)\n",
    "ben_2018 = retrained_stage3.predict(benign_data_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fcdd512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_byte_list = recon_metrices(infiltration_attack_2018, inf_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e7333f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5168979255392224\n"
     ]
    }
   ],
   "source": [
    "## Classification\n",
    "count_99 = len([i for i in mae_byte_list if i > 0.10])\n",
    "print(count_99 / len(mae_byte_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d197ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rand = pd.read_csv('Adv_all_DNN_truerandom.csv')\n",
    "df_rand = df_rand.loc[:, ~df_rand.columns.str.contains('^Unnamed')]\n",
    "adv_rand = df_rand.iloc[:,:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a2ee58a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/362 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "rand_adv = retrained_stage3.predict(adv_train)\n",
    "mae_byte_list = recon_metrices(adv_train, rand_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9f062472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015135789655768898\n"
     ]
    }
   ],
   "source": [
    "## Classification\n",
    "count_99 = len([i for i in mae_byte_list if i > 0.10])\n",
    "print(count_99 / len(mae_byte_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aace546",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Infiltration')\n",
    "cnt_inf, acc_inf = accuracy_calc(inf_2018)\n",
    "print(cnt_inf)\n",
    "print(acc_inf)\n",
    "print('DoS')\n",
    "cnt_dos, acc_dos = accuracy_calc(dos_2018)\n",
    "print(cnt_dos)\n",
    "print(acc_dos)\n",
    "print('DDoS')\n",
    "cnt_ddos, acc_ddos = accuracy_calc(ddos_2018)\n",
    "print(cnt_ddos)\n",
    "print(acc_ddos)\n",
    "print('Web')\n",
    "cnt_web, acc_web = accuracy_calc(web_2018)\n",
    "print(cnt_web)\n",
    "print(acc_web)\n",
    "print('Brute')\n",
    "cnt_brute, acc_brute = accuracy_calc(brute_2018)\n",
    "print(cnt_brute)\n",
    "print(acc_brute)\n",
    "print('Benign')\n",
    "cnt_ben, acc_ben = accuracy_calc(ben_2018)\n",
    "print(cnt_ben)\n",
    "print(1-acc_ben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CICIDS2017 Testing Retrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b219a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = retrained_stage1.predict(infiltration_attack)\n",
    "dos = retrained_stage1.predict(dos_attack)\n",
    "ddos = retrained_stage1.predict(ddos_attack)\n",
    "web = retrained_stage1.predict(web_attack)\n",
    "brute = retrained_stage1.predict(bruteforce_attack)\n",
    "ben = retrained_stage1.predict(benign_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Infiltration')\n",
    "cnt_inf, acc_inf = accuracy_calc(inf)\n",
    "print(cnt_inf)\n",
    "print(acc_inf)\n",
    "print('DoS')\n",
    "cnt_dos, acc_dos = accuracy_calc(dos)\n",
    "print(cnt_dos)\n",
    "print(acc_dos)\n",
    "print('DDoS')\n",
    "cnt_ddos, acc_ddos = accuracy_calc(ddos)\n",
    "print(cnt_ddos)\n",
    "print(acc_ddos)\n",
    "print('Web')\n",
    "cnt_web, acc_web = accuracy_calc(web)\n",
    "print(cnt_web)\n",
    "print(acc_web)\n",
    "print('Brute')\n",
    "cnt_brute, acc_brute = accuracy_calc(brute)\n",
    "print(cnt_brute)\n",
    "print(acc_brute)\n",
    "print('Benign')\n",
    "cnt_ben, acc_ben = accuracy_calc(ben)\n",
    "print(cnt_ben)\n",
    "print(1-acc_ben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0d5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db833da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f155d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
